;##############################################################################
;##############################################################################
;#
;#	DO NOT EDIT - file is being maintained by puppet
;#
;##############################################################################
;##############################################################################



;===================================================================
;                       IMPORTANT
;===================================================================
;
; 
; You can get documentation on the syntax of this file at:
; https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/ConfigurationFileFormat
; You can get documentation on the options for each section at:
; https://twiki.grid.iu.edu/bin/view/ReleaseDocumentation/ConfigurationFileHelp
;


[DEFAULT]
; Use this section to define variables that will be used in other sections
; For example, if you define a variable called dcache_root here
; you can use it in the gip section as %(dcache_root)s  (e.g. 
; my_vo_1_dir = %(dcache_root)s/my_vo_1
; my_vo_2_dir = %(dcache_root)s/my_vo_2

; Defaults, please don't modify these variables
unavailable = UNAVAILABLE
default = UNAVAILABLE

; Name these variables disable and enable rather than disabled and enabled
; to avoid infinite recursions
disable = False
enable = True

; You can modify the following and use them
localhost = <%= fqdn %>
admin_email = cms@listserv.unl.edu

;===================================================================
;                       Site Information
;===================================================================

[Site Information]
; The group option indicates the group that the OSG site should be listed in,
; for production sites this should be OSG, for vtb or itb testing it should be
; OSG-ITB
; 
; YOU WILL NEED TO CHANGE THIS
group = OSG

; The host_name setting should give the host name of the CE  that is being 
; configured, this setting must be a valid dns name that resolves
; 
; YOU WILL NEED TO CHANGE THIS
host_name = <%= fqdn %>

; The resource setting should be set to the same value as used in the OIM 
; registration at the goc 
; 
; YOU WILL NEED TO CHANGE THIS
resource = <%= hostname %>


; The resource_group setting should be set to the same value as used in the OIM 
; registration at the goc 
; 
; YOU WILL NEED TO CHANGE THIS
resource_group = Nebraska

; The sponsor setting should list the sponsors for your cluster, if your cluster
; has multiple sponsors, you can separate them using commas or specify the 
; percentage using the following format 'osg, atlas, cms' or 
; 'osg:10, atlas:45, cms:45'  
; 
; YOU WILL NEED TO CHANGE THIS
sponsor = uscms:80 local:20

; The site_policy setting should give an url that lists your site's usage
; policy 
site_policy = http://t2.unl.edu/site-policy

; The contact setting should give the name of the admin/technical contact
; for the cluster
; 
; YOU WILL NEED TO CHANGE THIS
contact = HCC

; The email setting should give the email address for the technical contact
; for the cluster 
; 
; YOU WILL NEED TO CHANGE THIS
email = cms@listserv.unl.edu

; The city setting should give the city that the cluster is located in
; 
; YOU WILL NEED TO CHANGE THIS
city = Lincoln, NE

; The country setting should give the country that the cluster is located in
; 
; YOU WILL NEED TO CHANGE THIS
country = USA

; The longitude setting should give the longitude for the cluster's location
; if you are in the US, this should be negative
; accepted values are between -180 and 180
; 
; YOU WILL NEED TO CHANGE THIS
longitude = -96.68

; The latitude setting should give the latitude for the cluster's location
; accepted values are between -90 and 90
; 
; YOU WILL NEED TO CHANGE THIS
latitude = 40.82


;===================================================================
; For the following job manager sections (LSF, SGE, PBS, Condor)
; you should delete the sections corresponding to job managers that 
; you are not using.  E.g. if you are just using Condor on your
; site, you can delete the LSF, SGE and PBS sections.
;===================================================================


;===================================================================
;                             Condor
;===================================================================


[Condor]
; This section has settings for configuring your CE for a Condor job manager

; The enabled setting indicates whether you want your CE to use a Condor job 
; manager
; valid answers are True or False
enabled = True

; The condor_location setting should give the location of condor install directory
condor_location = /usr

; The condor_location setting should give the location of condor config file,
; This is typically  etc/condor_config within the condor install directory.
; If you leave this set to %(unavailable)s, configure-osg will attempt to
; determine the correct value.
condor_config = /etc/condor/condor_config

; The job_contact setting should give the contact string for the jobmanager 
; on this CE (e.g. host.name/jobmanager-condor) 
job_contact = <%= fqdn %>/jobmanager-condor

; The util_contact should give the contact string for the default jobmanager
; on this CE (e.g. host.name/jobmanager)
util_contact = <%= fqdn %>/jobmanager

; The wsgram setting should be set to True or False depending on whether you
; wish to enable wsgram on this CE
wsgram = True


;===================================================================
;                              Managed Fork
;===================================================================


[Managed Fork]
; The enabled setting indicates whether managed fork is in use on the system
; or not. You should set this to True or False
enabled = False


;===================================================================
;                              Misc Services
;===================================================================


[Misc Services]
; If you have glexec installed on your worker nodes, enter the location
; of the glexec binary in this setting
glexec_location = /usr/sbin/glexec

; If you wish to use the ca certificate update service, set this setting to True, 
; otherwise keep this at false
; Please note that as of OSG 1.0, you have to use the ca cert updater or the RPM
; updates, pacman can not update the ca certs
use_cert_updater = False

; This setting should be set to the host used for gums host.  
; If your site is not using a gums host, you can set this to %(unavailable)s
gums_host = red-auth.unl.edu

; This setting should be set to one of the following: gridmap, prima, xacml 
; to indicate whether gridmap files, prima callouts, or prima callouts with xacml
; should be used
authorization_method = prima

; This setting indicates whether the osg index page generation will be run,
; by default this is not run
enable_webpage_creation = False

;===================================================================
;                         CEMon
;===================================================================

[Cemon]

; Default servers for production and itb OSG ress/bdii servers, please don't touch

; The current production osg servers
; Production ReSS server
osg-ress-servers = https://osg-ress-1.fnal.gov:8443/ig/services/CEInfoCollector[OLD_CLASSAD]
; Production BDII server
osg-bdii-servers = http://is1.grid.iu.edu:14001[RAW], http://is2.grid.iu.edu:14001[RAW]

; The current itb osg servers
; ITB ReSS server
itb-ress-servers = https://osg-ress-4.fnal.gov:8443/ig/services/CEInfoCollector[OLD_CLASSAD]
; ITB BDII server
itb-bdii-servers = http://is-itb1.grid.iu.edu:14001[RAW], http://is-itb2.grid.iu.edu:14001[RAW]
 

; The enable option indicates whether cemon should be enabled or 
; disabled.  It should be set to True or False
;
; You generally want Cemon enabled for any CE installation
enabled = True

; This setting indicates which servers ress information should
; be sent to.  Most sites should use the %(osg-ress-servers)s 
; setting so that the predefined variable giving the default
; osg production servers will be used, ITB admins can use 
; %(itb-ress-servers)s for default itb servers
;
; The server list should be formated as follows:
; server_uri[format],server_uri[format]
; see the variables at the top of this section for examples of this 
ress_servers = %(default)s

; This setting indicates which servers bdii information should
; be sent to.  Most sites should use the %(osg-bdii-servers)s 
; setting so that the predefined variable giving the default
; osg production servers will be used, ITB admins can use 
; %(itb-bdii-servers)s for default itb servers
; 
; The formatting for this are the same as the ress_servers setting 
bdii_servers = %(default)s

;===================================================================
;                         Gratia
;===================================================================

[Gratia]

; Default gratia servers
; 
; Please don't change these unless you have good reason to do so

; Variables for osg itb probes, CE installations should use the 
; jobmanager and metric probes 
;itb-jobmanager-gratia = jobmanager:gratia-osg-itb.opensciencegrid.org:80
;itb-gridftp-gratia = gridftp:gratia-osg-itb.opensciencegrid.org:80
;itb-metric-gratia = metric:rsv.grid.iu.edu:8880

; Variables for osg production probes, CE installations should use the 
; jobmanager and metric probes 
osg-jobmanager-gratia = jobmanager:rcf-gratia.unl.edu:8880
osg-gridftp-gratia = gridftp:rcf-gratia.unl.edu:8880
osg-metric-gratia = metric:rcf-gratia.unl.edu:8880
    

; The enable option indicates whether gratia should be enabled or 
; disabled.  It should be set to True or False
;
; You generally want Gratia enabled for any CE installation, in 
; addition SE installations may want to enable gratia to use 
; the gratia gridftp reporting
enabled = True


; This setting specifies the resource that gratia will use to report
; accounting information, on a CE if you leave this blank, gratia will
; use the resource setting from the Site Information section
;
resource = Red

; This setting indicates which probes should be enabled for gratia
; The list should be given as probe_name1:host1:port1, probe_name2:host2:port2 
; where probe_name is either jobmanager, metric, or gridftp
; host is a fully qualified domain name
; port is the port that the server is listening on
; CEs should have entries for jobmanager and metric probes
; SEs should use gridftp if they would like to enable gridftp transfer
; accounting 
; for convience admins can use %(osg-jobmanager-gratia)s,
; %(osg-gridftp-gratia)s, %(osg-metric-gratia)s for production sites
; and %(itb-jobmanager-gratia)s, %(itb-gridftp-gratia)s, 
; and %(itb-metric-gratia)s for ITB sites
probes = metric:rcf-gratia.unl.edu:8880, jobmanager:rcf-gratia.unl.edu:8880, gridftp:rcf-gratia.unl.edu:8880


;===================================================================
;                            RSV
;===================================================================


[RSV]
; The enable option indicates whether RSV should be enabled or disabled.  It should
; be set to True, False, or Ignore.  
;
; If you are using rsv-control to enable or disable specific metrics, you should set 
; this to Ignore so that your configuration does not get overwritten each time that
; configure-osg is run.
enabled = False


; The rsv_user option gives the user that the RSV service should use.  It must
; be a valid unix user account
; 
; If RSV is enabled, and this is blank or set to unavailable it will default to 
; the user 'rsvuser'
rsv_user = UNAVAILABLE


; This option will enable RSV record uploading to the central RSV collector at
; the GOC.  This is required for WLCG availability reporting.
;
; Note: It no longer matters if your site is production or ITB.  All records
;       will be reported to the same place.
;
; Set this to True or False
enable_gratia = True

; This option will set the gratia_collector you will report to.  Leave this 
; option commented out to use the default Gratia collector.  If you with to
; report to a different collector instead of the default OSG collector then
; supply the hostname:port here.  Note: this must be of the form hostname:port
; gratia_collector = <your host>:<your port>



; You must use a certificate with RSV.  Either you can use a service certificate
; or a user certificate.  Using a service certificate is highly recommended
; because it will be automatically renewed for you with each job that runs.
;
; To use a service certificate, set the following variables:
;   - use_service_cert
;   - rsv_cert_file
;   - rsv_key_file
;   - rsv_proxy_out_file
;
; To use a user certificate, set the following variable:
;   - proxy_file

; Set use_service_cert to True if you would like to use a service
; certificate with RSV. 
;
; NOTE: This can't be used if you specify multiple CEs or GUMS hosts
use_service_cert = False

; This setting will be used if you have enabled use_service_cert.  
; This should point to the public key file (pem) for your service 
; certificate.
; 
; If this is left blank or set to UNAVAILABLE  and the use_service_cert 
; setting is enabled, it will default to /etc/grid-security/rsvcert.pem
rsv_cert_file  = UNAVAILABLE

; This setting will be used if you have enabled the use_service_cert.  
; This should point to the private key file (pem) for your service 
; certificate.
;
; If this is left blank or set to UNAVAILABLE and the use_service_cert 
; setting is enabled, it will default to /etc/grid-security/rsvkey.pem
rsv_key_file  = UNAVAILABLE


; This setting will be used if you have enabled the use_service_cert.
; This should point to the location of the RSV proxy file.
;
; If this is left blank or set to UNAVAILABLE and the use_service_cert 
; setting is enabled, it will default to /tmp/rsvproxy
rsv_proxy_out_file = UNAVAILABLE


; If you don't use a service certificate for RSV, you will need to specify a 
; proxy file that RSV should use in the proxy_file setting.  If you use this
; option you need to renew this proxy file periodically.
; This needs to be set if use_service_cert is disabled.  
proxy_file = UNAVAILABLE


; The enable_ce_probes option enables or disables the RSV CE probes.  If you
; enable this you should also set the ce_hosts option as well.
;
; Set this to true or false. 
enable_ce_probes = True

; The ce_hosts options lists the FQDN of the CEs that the RSV CE metrics should
; run against.  This is a list of FQDNs separated by a comma, for example:
;   ce_hosts = ce.example.com, ce2.example.com, ce3.example.com
;
; This setting will be used if the enable_ce_probes option is enabled.  If this
; is set to UNAVAILABLE or left blank, then it will default to the hostname
; setting for this CE.
ce_hosts = UNAVAILABLE


; The enable_gridftp_probes option enables or disables the RSV gridftp metrics.
; If you enable this, you should also set the ce_hosts or gridftp_hosts option
; as well.
;
; Set this to True or False. 
enable_gridftp_probes = False

; The gridftp_hosts options lists the FQDN of the gridftp servers that the RSV
; GridFTP metrics should monitor.  This is be a list of FQDNs separated by a
; comma, for example:
; gridftp_hosts = gridftp.example.com, gridftp2.example.com, gridftp3.example.com
;
; This setting will be used if the enable_gridftp_probes option is enabled.  If
; this is set to UNAVAILABLE or left blank then it will default to the hostname 
; setting for this CE.
gridftp_hosts = UNAVAILABLE


; The gridftp_dir option gives the directory on the gridftp servers that the 
; RSV GridFTP probes should try to write and read from.
;
; This setting will be used if the enable_gridftp_probes option is enabled. It
; will default to /tmp if left blank or set to UNAVAILABLE 
gridftp_dir = UNAVAILABLE


; This setting specifies which RSV Gratia metrics should be run.  Set this to 
; UNAVAILABLE to disable gratia metrics, otherwise list the Gratia metrics
; to run separated by commas.  Valid metrics are:
; metric, condor, pbs, lsf, sge, hadoop-transfer, gridftp-transfer
;
; If you are monitoring a CE, you probably want to run the 'metric' metric, the
; appropriate metric for your batch system, and 'condor' if you are using
; Managed-Fork
;
; For example, on a CE using PBS and the Managed-Fork, you will probably use:
; gratia_probes = metric, pbs, condor
gratia_probes = UNAVAILABLE


; The enable_gums_probes option enables or disables the RSV gums metrics.  If 
; you enable this you should also set the gums_hosts option as well.
;
; Set this to True or False. 
enable_gums_probes = False

; The gums_hosts options lists the FQDN of the GUMS server that the RSV GUMS 
; metrics should monitor.  This should be a list of FQDNs separated by a comma:
; gums_hosts = gums.example.com, gums2.example.com, ce.example.com
;
; This option will be used if the enable_gums_probes option is enabled.
gums_hosts = UNAVAILABLE


; The enable_srm_probes option enables or disables the RSV SRM metrics.  If you
; you enable this, you should also set the srm_hosts option as well.
;
; Set this to True or False. 
enable_srm_probes = False

; The srm_hosts options lists the FQDN of the SRM servers that the RSV SRM
; metrics should monitor. This should be a list of FQDNs separated by a comma.
; You can specify the port on a host using host:port.  For example:
; srm_hosts = srm.example.com:8443, srm2.example.com:10443, srm3.example.com
;
; This or ce_hosts should be set if the enable_srm_probes option is enabled.  If 
; this is set to UNAVAILABLE or left blank it will default to the hostname 
; setting for this CE.
srm_hosts = UNAVAILABLE

; The srm_dir options gives the directory  on the srm servers that the 
; RSV SRM probes should try to write and read from. 
;
; This must be set if the enable_srm_probes option is enabled. 
srm_dir = UNAVAILABLE

; This option gives the webservice path that SRM metrics need along with the
; host: port. For dcache installations this should work if left blank or left
; out.  However Bestman-Xrootd SEs normally use srm/v2/server as the web service
; path, and so Bestman-Xrootd admins will have to pass this option with the
; appropriate value (for example: "srm/v2/server") for the SRM metrics to work
; on their SE.
srm_webservice_path = UNAVAILABLE


; enable_local_probes will enable some 'local' metrics to run against the host
; that RSV is running on.  Currently there are local probes to monitor the
; validity of the hostcert, containercert, and httpcert.
enable_local_probes = True


; The setup_for_apache option indicates whether RSV should create a webpage that
; can be used to view the status of the RSV tests.  Enabling this is highly
; encouraged.
;
; Set this to True or False
setup_for_apache = True


; The setup_rsv_nagios option indicates whether RSV will report information to a
; local nagios instance.
;
; Set this to True or False
setup_rsv_nagios = False

; The rsv_nagios_conf_file option indicates the location of the RSV nagios file
; to use for configuration details.  If this is set to UNAVAILABLE then 
; $VDT_LOCATION/osg-rsv/config/rsv-nagios.conf will be used.  You should fill
; this file in with the appropriate information.
rsv_nagios_conf_file = UNAVAILABLE


;===================================================================
;                            Storage 
;===================================================================

[Storage]
;
; Several of these values are constrained and need to be set in a way
; that is consistent with one of the OSG storage models
;
; Please refer to the OSG release documentation for an indepth explanation 
; of the various storage models and the requirements for them

; If you have a SE available for your cluster and wish to make it available 
; to incoming jobs, set se_available to True, otherwise set it to False
se_available = True

; If you indicated that you have an se available at your cluster, set default_se to
; the hostname of this SE, otherwise set default_se to UNAVAILABLE
default_se = srm.unl.edu

; The grid_dir setting should point to the directory which holds the files 
; from the OSG worker node package, it should be visible on all of the computer
; nodes (read access is required, worker nodes don't need to be able to write) 
; 
; YOU WILL NEED TO CHANGE THIS
grid_dir = /opt/osgwn1.2.15

; The app_dir setting should point to the directory which contains the VO 
; specific applications, this should be visible on both the CE and worker nodes
; but only the CE needs to have write access to this directory
; 
; YOU WILL NEED TO CHANGE THIS
app_dir = /opt/osg/app

; The data_dir setting should point to a directory that can be used to store 
; and stage data in and out of the cluster.  This directory should be readable
; and writable on both the CE and worker nodes
; 
; YOU WILL NEED TO CHANGE THIS
data_dir = /opt/osg/data

; The worker_node_temp directory should point to a directory that can be used 
; as scratch space on compute nodes, it should allow read and write access on the 
; worker nodes but can be local to each worker node
; 
; YOU WILL NEED TO CHANGE THIS
worker_node_temp = /scratch

; The site_read setting should be the location or url to a directory that can 
; be read to stage in data, this is an url if you are using a SE 
; 
; YOU WILL NEED TO CHANGE THIS
site_read = %(unavailable)s

; The site_write setting should be the location or url to a directory that can 
; be write to stage out data, this is an url if you are using a SE 
; 
; YOU WILL NEED TO CHANGE THIS
site_write = %(unavailable)s

;===================================================================
;                              Monalisa
;===================================================================

[MonaLisa]
; Set the enabled setting to True if you have monalisa installed and wish to 
; use it, otherwise set it to False 
enabled = %(disable)s

; If you want monalisa to use it's vo modules, set the use_vo_modules setting
; to true, otherwise set this to False
use_vo_modules = %(default)s

; The ganglia_support setting should be enabled if you are using ganglia on
; your cluster and you wish monalisa to use it as well
ganglia_support = %(disable)s

; If you've enabled ganglia support, you should enter the hostname of the 
; ganglia server in the ganglia_host option
ganglia_host = %(unavailable)s

; If you've enabled ganglia support, you should enter the port that ganglia
; is running on
ganglia_port = %(default)s

; Set this to the monitor group that monalisa will report, by default this 
; will be set to the group set in the Site Information section
monitor_group = %(default)s

; This setting should be set to Y or N depending on whether you
; want monalisa to autoupdate itself, by default this is set to N
auto_update = %(default)s

; This setting should be set to the user account that monalisa will
; run under, by default this is set to daemon
user = %(default)s

;===================================================================
;                             Squid
;===================================================================

[Squid]
; Set the enabled setting to True if you have squid installed and wish to 
; use it, otherwise set it to False 
enabled = True

; If you are using squid, specify the location of the squid server in the 
; location setting, this can be a path if squid is installed on the same
; server as the CE or it can be a hostname
location = red-squid1.unl.edu

; If you are using squid, use the policy setting to indicate which cache
; replacement policy squid is using
policy = LRU

; If you are using squid, use the cache_size setting to indicate which the 
; size of the disk cache that squid is using
cache_size = 164864

; If you are using squid, use the memory_size setting to indicate which the 
; size of the memory cache that squid is using
memory_size = 512


;===================================================================
;                              GIP
;===================================================================

[GIP]

; ========= These settings must be changed ==============

;; This setting indicates the batch system that GIP should query
;; and advertise
;; This should be the name of the batch system in lowercase
batch = condor
;; Options include: pbs, lsf, sge, or condor

; ========= These settings can be left as is for the standard install ========

;; This setting indicates whether GIP should advertise a gsiftp server
;; in addition to a srm server, if you don't have a srm server, this should
;; be enabled
;; Valid options are True or False
advertise_gsiftp = False

;; This should be the hostname of the gsiftp server that gip will advertise
gsiftp_host = %(localhost)s

;; This setting indicates whether GIP should query the gums server.
;; Valid options are True or False
advertise_gums = %(disable)s

cluster_name = red.unl.edu

<% osgCEList.delete_if { |ce| ce == fqdn } -%>
other_ces = <% osgCEList.each do |ce| %><% if ce == osgCEList.last %><%= ce %><% else %><%= ce %>, <% end %><% end %>

;===================================================================
;                          Subclusters
;===================================================================

; For each subcluster, add a new subcluster section.
; Each subcluster name must be unique for the entire grid, so make sure to not
; pick anything generic like "MAIN".  Each subcluster section must start with
; the words "Subcluster", and cannot be named "CHANGEME".

; There should be one subcluster section per set of homogeneous nodes in the
; cluster.

; This data is used for our statistics collections in the OSG, so it's important
; to keep it up to date.  This is important for WLCG sites as it will be used
; to determine your progress toward your MoU commitments!

; If you have many similar subclusters, then feel free to collapse them into
; larger, approximately-correct groups.

; See example below:

[Subcluster T2_US_Nebraska Dell SC1435]
name = T2_US_Nebraska Dell SC1435
node_count = 40
ram_mb = 8053
cpu_model = Dual-Core AMD Opteron(tm) Processor 2216
cpu_vendor = AMD
cpu_speed_mhz = 2400
cpu_platform = x86_64
cpus_per_node = 2
cores_per_node = 4
inbound_network = FALSE
outbound_network = TRUE
swap_mb = 20000
; HEPSPEC = 8

[Subcluster T2_US_Nebraska Dell R410]
name = T2_US_Nebraska Dell R410
node_count = 12
ram_mb = 24096
cpu_model = Intel(R) Xeon(R) CPU           E5520  @ 2.27GHz
cpu_vendor = Intel
cpu_speed_mhz = 2261
cpu_platform = x86_64
cpus_per_node = 2
cores_per_node = 8
inbound_network = FALSE
outbound_network = TRUE
swap_mb = 10000
; HEPSPEC = 8

[Subcluster T2_US_Nebraska Dell R510]
name = T2_US_Nebraska Dell R510
node_count = 40
ram_mb = 24096
cpu_model = Intel(R) Xeon(R) CPU           E5530  @ 2.40GHz
cpu_vendor = Intel
cpu_speed_mhz = 2400
cpu_platform = x86_64
cpus_per_node = 2
cores_per_node = 8
inbound_network = FALSE
outbound_network = TRUE
swap_mb = 15000
; HEPSPEC = 8

[Subcluster T2_US_Nebraska Dell R710]
name = T2_US_Nebraska Dell R710
node_count = 28
ram_mb = 24096
cpu_model = Intel(R) Xeon(R) CPU           E5520  @ 2.27GHz
cpu_vendor = Intel
cpu_speed_mhz = 2261
cpu_platform = x86_64
cpus_per_node = 2
cores_per_node = 8
inbound_network = FALSE
outbound_network = TRUE
swap_mb = 10000
; HEPSPEC = 8

[Subcluster T2_US_Nebraska Sun x2200]
name = T2_US_Nebraska Sun x2200
node_count = 70
ram_mb = 16058
cpu_model = Quad-Core AMD Opteron(tm) Processor 2354
cpu_vendor = AMD
cpu_speed_mhz = 2211
cpu_platform = x86_64
cpus_per_node = 2
cores_per_node = 8
inbound_network = FALSE
outbound_network = TRUE
swap_mb = 20000
; HEPSPEC = 8

[Subcluster T2_US_Nebraska Sun x4275]
name = T2_US_Nebraska Sun x4275
node_count = 4
ram_mb = 24084
cpu_model = Intel(R) Xeon(R) CPU           E5520  @ 2.27GHz
cpu_vendor = Intel
cpu_speed_mhz = 2261
cpu_platform = x86_64
cpus_per_node = 2
cores_per_node = 8
inbound_network = FALSE
outbound_network = TRUE
swap_mb = 10000
; HEPSPEC = 8



;===================================================================
;                             SE
;===================================================================

[SE Hadoop]
name = T2_Nebraska_Hadoop
srm_endpoint = httpg://dcache07.unl.edu:8443/srm/v2/server
provider_implementation = bestman
implementation = bestman
version = 2.2.1.2.e1
default_path = /mnt/hadoop/user/VONAME
use_df = True
mount_point = /,/
hadoop_path = /mnt/hadoop/user/uscms01/pnfs/unl.edu/data4/cms/store
;allowed_vos = cms

[SE Hadoop2]
name = T2_Nebraska_Storage
srm_endpoint = httpg://srm.unl.edu:8443/srm/v2/server
provider_implementation = bestman
implementation = bestman
version = 2.2.1.2.e1
default_path = /mnt/hadoop/user/VONAME
use_df = True 
mount_point = /,/
hadoop_path = /mnt/hadoop/user/uscms01/pnfs/unl.edu/data4/cms/store
;allowed_vos=cms

[SE HadoopOSG]
name = T2_Nebraska_OSG
srm_endpoint = httpg://red-srm1.unl.edu:8443/srm/v2/server
provider_implementation = bestman
implementation = bestman
version = 2.2.1.2.e1
default_path = /mnt/hadoop/user/VONAME
use_df = True 
mount_point = /,/
hadoop_path = /mnt/hadoop/user/
